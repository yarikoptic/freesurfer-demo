/**
 * @file  mriframegpu.hpp
 * @brief Holds MRI frame template for the GPU
 *
 * Holds an MRI frame template type for the GPU
 */
/*
 * Original Author: Richard Edgar
 * CVS Revision Info:
 *    $Author: nicks $
 *    $Date: 2010/10/22 22:40:14 $
 *    $Revision: 1.41.2.1 $
 *
 * Copyright (C) 2002-2008,
 * The General Hospital Corporation (Boston, MA). 
 * All rights reserved.
 *
 * Distribution, usage and copying of this software is covered under the
 * terms found in the License Agreement file named 'COPYING' found in the
 * FreeSurfer source code root directory, and duplicated here:
 * https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferOpenSourceLicense
 *
 * General inquiries: freesurfer@nmr.mgh.harvard.edu
 *
 */

#ifndef MRI_FRAME_CUDA_H
#define MRI_FRAME_CUDA_H

#include <cstdlib>
#include <cstdio>

#include <iostream>
#include <iomanip>

#include <cuda_runtime.h>

#include "mri.h"

#include "volumegpu.hpp"
#include "affinegpu.hpp"

#include "cudatypeutils.hpp"
#include "cudacheck.h"

// ==================================================================

namespace GPU {

  namespace Classes {

     
    //! Ancillary class for use in kernel calls
    /*!
      This is an auxillary class, for use in actual
      kernel calls.
      Host side functions should simply use the MRIframeGPU
      class.
      The kernel invocation has to be on a call-by-value
      copy, so we want to make sure that the destructor
      doesn't go zapping memory allocations prematurely.
      Most of its functionality is provided by the base
      class VolumeArgGPU.

      To use in a kernel, simply declare the kernel
      arguments to be of this type:
      \code
      template<typename T, typename U>
      __global__ void MyKernel( const MRIframeOnGPU<T> a,
                                MRIframeOnGPU<U> b ) {
	 ...
      }
      \endcode
      Since appropriate conversion operators are provided,
      the kernel can be invoked simply with MRIframeGPU
      arguments:
      \code
      MRIframeGPU<T> a;
      MRIframeGPU<U> b;
      MyKernel<T,U><<<grid,threads>>>( a, b );
      \endcode
      The necessary casts and copies will occur automatically.
      @see VolumeArgGPU
      @see MRIframeGPU
    */
    template<typename T>
    class MRIframeOnGPU : public VolumeArgGPU<T> {
    public:
      
      // --------------------------------------------------------
      // Constructors
      
      //! Default constructor
      MRIframeOnGPU<T>( void ) : VolumeArgGPU<T>() {};
      
     
      //! Constructor from MRIframeGPU
      MRIframeOnGPU<T>( const VolumeArgGPU<T>& src ) :
	VolumeArgGPU<T>(src) {};
      

      // --------------------------------------------------------

      //! Out of range value
      static const T kOutOfRangeVal = 0;
      
      // --------------------------------------------------------
      // Subscripting operators
      
      //! RHS Subscripting operator
      __device__ T operator() ( const unsigned int ix,
				const unsigned int iy,
				const unsigned int iz ) const {
	/*!
	  This version of the subscripting operator is safe.
	  It overrides the unsafe version in VolumeArgGPU
	  It bounds checks the requested dimensions,
	  and returns kOutofRangeVal if out of range
	*/
	if( this->InVolume( ix, iy, iz ) ) {
	  // Use the unsafe operator() of the base class
	  return( this->VolumeArgGPU<T>::operator()( ix, iy, iz ) );
	} else {
	  return( this->kOutOfRangeVal );
	}
      }
      

      //! LHS subscripting operator
      __device__ T& operator() ( const unsigned int ix,
				 const unsigned int iy, 
				 const unsigned int iz ) {
	/*!
	  This is a thin wrapper around the base class operator.
	  For reasons which are probably lost in the depths of the
	  C++ standard (to do with resolving overloaded and overridden
	  methods), this is necessary to use subscripting on the LHS
	  of an expression
	*/
	return( this->VolumeArgGPU<T>::operator()( ix, iy, iz ) );
      }

      //! Utility function to convert float to the class' datatype
      inline
      __device__ T ConvertFloat( const float in ) const {
	/*!
	  This template is specialised for each supported class.
	  The unspecialised default will write a constant
	  negative value
	*/
	return( -1 );
      }
      
      // --------------------------------------------------------

      //! Clamps input integer into range
      __device__ unsigned int ClampCoord( const int i,
					  const unsigned int iMax ) const {
	/*!
	  Performs clamping on the input index.
	  Negative values are set to 0, values greater than iMax-1 are
	  set to iMax-1
	*/
	if( i < 0 ) {
	  return 0;
	} else if( i > (iMax-1) ) {
	  return( iMax-1 );
	} else {
	  return i;
	}
      }
    };

    // ================================================================


    //! Templated class to hold an MRI frame on the GPU
    /*!
      This class is provided to host code to hold one frame
      of MRI data on the GPU.
      The data are held in linear memory, which is padded to
      optimise CUDA memory accesses.
      The data can also be copied into a CUDA array, in order
      to enable texturing.
      Most of the device-side functionality is provided by
      the VolumeGPU base class.
      On the host side, this derived class provides easy methods
      of copying data to the GPU.
      This class is templated based on the stored data type.
      As a result, switch blocks (and specialised templates) are
      often necessay to handle incoming MRI structures.
      @see MRIframeOnGPU
    */
    template<typename T>
    class MRIframeGPU : public VolumeGPU<T> {
    public:
  
      // --------------------------------------------------------
      // Constructors & destructors

      //! Default constructor does nothing
      MRIframeGPU<T>( void ) : VolumeGPU<T>(),
			       thick(0),
			       sizes(make_float3(0,0,0)),
			       d_i_to_r(),
			       d_r_to_i() {};

      //! Conversion operator to MRIframeOnGPU
      operator MRIframeOnGPU<T>( void ) const {
	VolumeArgGPU<T> vag( *this );

	return( MRIframeOnGPU<T>( vag ) );
      }

      // --------------------------------------------------------
      // Public data (should probably be private)
      
      AffineTransformation d_i_to_r;
      AffineTransformation d_r_to_i;

      // --------------------------------------------------------
      // Data accessors

      //! Return information about the file version
      const char* VersionString( void ) const {
	return "$Id: mriframegpu.hpp,v 1.41.2.1 2010/10/22 22:40:14 nicks Exp $";
      }
      
      //! Return the 'thick' field
      float GetThickness( void ) const {
	return( this->thick );
      }

      //! Return the 'sizes' field
      float3 GetSizes( void ) const {
	return( this->sizes );
      }

      // --------------------------------------------------------
      // Memory manipulation
      
      // -----

      //! Extracts frame dimensions from a given MRI and allocates the memory
      void Allocate( const MRI* src ) {
	/*!
	  Extracts frame dimensions from the supplied MRI, and uses
	  this to allocate the appropriate amount of device
	  memory.
	  It first performs a sanity check on the type field
	  of the MRI structure
	  @param[in] src The MRI to use as a template
	*/
	
	// Sanity checks
	if( src->type != this->MRItype()  ) {
	  std::cerr << __PRETTY_FUNCTION__
		    << ": MRI type mismatch against "
		    << src->type << std::endl;
	  exit( EXIT_FAILURE );
	}

	
	dim3 myDims = make_uint3( src->width, src->height, src->depth );

	this->VolumeGPU<T>::Allocate( myDims );
      }

      // -----

      //! Allocates matching storage of possibly different type
      template<typename U>
      void Allocate( const MRIframeGPU<U>& src ) {
	/*!
	  Some algorithms require intermediate results to be
	  stored in higher precision.
	  These will require identically dimensioned MRIframeGPU
	  classes, but of a different type.
	  This method clones the dimensions of the given source
	  frame, but allocates space for its own type.
	*/
	this->VolumeGPU<T>::Allocate( src );
      }


      // --------------------------------------------------------
      // Data transfer
      
      //! Sends the given MRI frame and the scalar data
      void Send( const MRI* src,
		 const unsigned int iFrame,
		 void* const h_work = NULL,
		 const cudaStream_t stream = 0 ) {
	
	// Copy the scalars over
	this->thick = src->thick;
	
	this->sizes = make_float3( src->xsize,
				   src->ysize,
				   src->zsize );

	// Send the transforms
	this->d_r_to_i.SetTransform( src->r_to_i__ );
	this->d_i_to_r.SetTransform( src->i_to_r__ );
	
	this->SendFrame( src, iFrame, h_work, stream );
      }

      //! Send the given MRI frame to the GPU
      void SendFrame( const MRI* src,
		      const unsigned int iFrame,
		      void* const h_work = NULL,
		      const cudaStream_t stream = 0 ) {
	/*!
	  Sends the given MRI frame to the GPU.
	  Optional arguments can be used to supply page-locked
	  host memory for the transfer, and a stream in which
	  to perform the transfer.
	  If supplied, the array h_work must be at least
	  GetBufferSize() bytes long.
	  Furthermore, the calling routine is responsible
	  for synchronisation
	  @param[in] src The MRI we wish to send to the GPU
	  @param[in] iFrame Which frame of the MRI we wish to send
	  @param h_work Optional pagelocked host memory
	  @param[in] stream Optional CUDA stream for the copy
	*/
	
	T* h_data;
	
	// Start with some sanity checks
	this->VerifyMRI( src );
	
	if( iFrame >= static_cast<unsigned int>(src->nframes) ) {
	  std:: cerr << __FUNCTION__
		     << ": Bad frame requested " << iFrame
		     << std::endl;
	  exit( EXIT_FAILURE );
	}

	// See if we need to allocate workspace
	const size_t bSize = this->BufferSize();
	// See if we were supplied with workspace
	if( h_work != NULL ) {
	  h_data = reinterpret_cast<T*>(h_work);
	} else {
	  // Allocate contiguous host memory
	  CUDA_SAFE_CALL( cudaHostAlloc( (void**)&h_data,
					 bSize,
					 cudaHostAllocDefault ) );
	}
	
	
	// Extract the data
	this->ExhumeFrame( src, h_data, iFrame );
	
	// Do the copy
	this->SendBuffer( h_data, stream );
	
	// Release host memory if needed
	if( h_work == NULL ) {
	  CUDA_SAFE_CALL( cudaStreamSynchronize( stream ) );
	  CUDA_SAFE_CALL( cudaFreeHost( h_data ) );
	}
      }
      
      // -----
      
      //! Receives the given MRI frame and the scalar data
      void Recv( MRI* dst,
		 const unsigned int iFrame,
		 void* const h_work = NULL,
		 const cudaStream_t stream = 0 ) const {

	// Retrieve the scalars
	dst->thick = this->thick;
	dst->xsize = this->sizes.x;
	dst->ysize = this->sizes.y;
	dst->zsize = this->sizes.z;

	this->RecvFrame( dst, iFrame, h_work, stream );
      }

      //! Receives the given MRI frame from the GPU
      void RecvFrame( MRI* dst,
		      const unsigned int iFrame,
		      void* const h_work = NULL,
		      const cudaStream_t stream = 0 ) const {
	/*!
	  Retrieves the given MRI frame from the GPU.
	  Optional arguments can be used to supply page-locked
	  host memory for the transfer, and a stream in which
	  to perform the transfer.
	  If supplied, the array h_work must be at least
	  GetBufferSize() bytes long
	*/
	
	T* h_data;
	
	// Start with sanity checks
	this->VerifyMRI( dst );
	
	if( iFrame >= static_cast<unsigned int>(dst->nframes) ) {
	  std:: cerr << __FUNCTION__
		     << ": Bad frame requested " << iFrame
		     << std::endl;
	  exit( EXIT_FAILURE );
	}

	
	
	// See about buffers
	const size_t bSize = this->BufferSize();
	
	// Allocate contiguous host memory if needed
	if( h_work != NULL ) {
	  h_data = reinterpret_cast<T*>(h_work);
	} else {
	  CUDA_SAFE_CALL( cudaHostAlloc( (void**)&h_data,
					 bSize,
					 cudaHostAllocDefault ) );
	}
	
	// Retrieve from GPU
	this->RecvBuffer( h_data, stream );

	CUDA_SAFE_CALL( cudaStreamSynchronize( stream ) );
	
	// Retrieve from contiguous RAM
	this->InhumeFrame( dst, h_data, iFrame );
	
	// Release host memory
	if( h_work == NULL ) {
	  CUDA_SAFE_CALL( cudaFreeHost( h_data ) );
	}
      }


      // -----

      // ----------------------------------------------------------------------
      //! Method to sanity check MRI
      void VerifyMRI( const MRI* mri ) const {
	/*!
	  A very simple routine to check that both the type
	  and dimensions of the current object match those
	  of the given MRI structure.
	*/
	
	if( mri->type != this->MRItype()  ) {
	  std::cerr << __PRETTY_FUNCTION__
		    << ": MRI type mismatch against "
		    << mri->type << std::endl;
	  exit( EXIT_FAILURE );
	}
	
	if( !this->CheckDims( mri ) ) {
	  std::cerr << __PRETTY_FUNCTION__
		    << ": Size mismatch"
		    << std::endl;
	  exit( EXIT_FAILURE );
	}
      }
      
      //! Method to return MRI type (has specialisations below)
      int MRItype( void ) const {
	/*!
	  Returns the type of data held in a form that the
	  rest of the Freesurfer package will recognise.
	  This is implemented as a set of specialised templates.
	*/
	return(-1);
      }
      
 
    private:
      // --------------------------------------------------------------------
    
      //! Mirror of the 'thick' field of an MRI
      float thick;

      //! Mirror of the {x|y|z}size fields (the voxel sizes)
      float3 sizes;

      //! Function to sanity check dimensions
      bool CheckDims( const MRI* mri ) const {

	const dim3 mriDims = make_uint3( mri->width,
					 mri->height,
					 mri->depth );
	
	return( mriDims == this->dims );
      }
      
      
      // ----------------------------------------------------------------------
      // Functions for converting MRI frames data to and from contiguous memory
      
      //! Copies a single frame into contiguous memory
      void ExhumeFrame( const MRI* src,
			T *h_slab,
			const unsigned int iFrame ) const {
	/*!
	  Copies a single MRI frame into contiguous memory on the host.
	  Assumes that all the memory has been allocated and GPU dimensions set,
	  so everything is not fanatically verified.
	  The name of this method should not be taken as a value judgement
	  of the CPU-side datastructure.
	  @param[in] src The source MRI
	  @param[out] h_slab Pointer to the destination array (must be already allocated)
	  @param[in] iFrame Which frame to grab
	*/
	
	// Start with a few sanity checks
	if( iFrame >= static_cast<unsigned int>(src->nframes) ) {
	  std::cerr << __FUNCTION__
		    << ": iFrame out of range"
		    << std::endl;
	  exit( EXIT_FAILURE );
	}
	
	if( h_slab == NULL ) {
	  std::cerr << __FUNCTION__
		    << ": h_slab unallocated"
		    << std::endl;
	  exit( EXIT_FAILURE );
	}
	
	this->VerifyMRI( src );
	
	
	// Main extraction loop
	for( unsigned int iz=0; iz<this->dims.z; iz++ ) {
	  for( unsigned int iy=0; iy<this->dims.y; iy++ ) {
	    unsigned int iStart = this->Index1D( 0, iy, iz );
	    
	    this->ExhumeRow( src, &( h_slab[iStart] ), iy, iz, iFrame );
	  }
	} 
      }
      
      // -----

      //! Copies contiguous memory to an MRI frame
      void InhumeFrame( MRI* dst,
			const T *h_slab,
			const unsigned int iFrame ) const {
	/*!
	  Copies a block of contiguous host memory on the host
	  into an MRI frame.
	  Assumes that everything is all properly allocated,
	  so things are not fanatically verified
	*/
	
	// Start with a few sanity checks
	if( iFrame >= static_cast<unsigned int>(dst->nframes) ) {
	  std::cerr << __FUNCTION__
		    << ": iFrame out of range"
		    << std::endl;
	  exit( EXIT_FAILURE );
	}
	
	if( h_slab == NULL ) {
	  std::cerr << __FUNCTION__
		    << ": h_slab unallocated"
		    << std::endl;
	  exit( EXIT_FAILURE );
	}
	
	this->VerifyMRI( dst );
	
	// Main extraction loop
	for( unsigned int iz=0; iz<this->dims.z; iz++ ) {
	  for( unsigned int iy=0; iy<this->dims.y; iy++ ) {
	    unsigned int iStart = this->Index1D( 0, iy, iz );
	
	    this->InhumeRow( dst, &( h_slab[iStart] ), iy, iz, iFrame );
	  }
	}
      }
      
      // -----
      
      //! Wrapper around memcpy for MRI->contiguous transfers
      void ExhumeRow( const MRI* src,
		      T *h_slab,
		      const unsigned int iy,
		      const unsigned int iz,
		      const unsigned int iFrame ) const {
	/*!
	  Specialised method to copy a row of an MRI frame
	  into contiguous memory.
	  The row of x voxels are specified by iy, iz and iFrame.
	  This default method aborts the program
	*/
	
	std::cerr << __PRETTY_FUNCTION__
		  << ": Unrecognised data type "
		  << src->type << std::endl;
	exit( EXIT_FAILURE );
      }

      // -----

      //! Wrapper around memcpy for contiguous->MRI transfers
      void InhumeRow( MRI* dst,
		      const T *h_slab,
		      const unsigned int iy,
		      const unsigned int iz,
		      const unsigned int iFrame ) const {
	/*!
	  Specialised method to copy a chunk of contiguous
	  memory into a row of an MRI frame.
	  The row of x voxels are specified by iy, iz and iFrame.
	  This default method aborts the program
	*/
	
	std::cerr << __PRETTY_FUNCTION__
		  << ": Unrecognised data type "
		  << dst->type << std::endl;
	exit( EXIT_FAILURE );
      }
      
      
    };


    // Declarations of specialised methods
    
    template<> int MRIframeGPU<unsigned char>::MRItype( void ) const;
    template<> int MRIframeGPU<short>::MRItype( void ) const;
    template<> int MRIframeGPU<float>::MRItype( void ) const;
    


    template<>
    void MRIframeGPU<unsigned char>::ExhumeRow( const MRI* src,
						unsigned char* h_slab,
						const unsigned int iy,
						const unsigned int iz,
						const unsigned int iFrame ) const;
    template<>
    void MRIframeGPU<short>::ExhumeRow( const MRI* src,
					short* h_slab,
					const unsigned int iy,
					const unsigned int iz,
					const unsigned int iFrame ) const;
    template<>
    void MRIframeGPU<float>::ExhumeRow( const MRI* src,
					float* h_slab,
					const unsigned int iy,
					const unsigned int iz,
					const unsigned int iFrame ) const;
    


    template<>
    void MRIframeGPU<unsigned char>::InhumeRow( MRI* dst,
						const unsigned char* h_slab,
						const unsigned int iy,
						const unsigned int iz,
						const unsigned int iFrame ) const;
    template<>
    void MRIframeGPU<short>::InhumeRow( MRI* dst,
					const short* h_slab,
					const unsigned int iy,
					const unsigned int iz,
					const unsigned int iFrame ) const;
    template<>
    void MRIframeGPU<float>::InhumeRow( MRI* dst,
					const float* h_slab,
					const unsigned int iy,
					const unsigned int iz,
					const unsigned int iFrame ) const;
    
    // ======================================================================

   

    template<> __device__
    inline
    unsigned char MRIframeOnGPU<unsigned char>::ConvertFloat( const float in ) const {
      // Copy 'nint' from utils.c
      return( static_cast<unsigned char>( in+0.5f ) );
    }

    template<> __device__
    inline
    short MRIframeOnGPU<short>::ConvertFloat( const float in ) const {
      // Copy 'nint' from utils.c
      return( static_cast<short>( in+0.5f ) );
    }

    template<> __device__
    inline
    float MRIframeOnGPU<float>::ConvertFloat( const float in ) const {
      return( in );
    }
    
  }
}


#endif
